
Our wine model had an R-squared value
of 0.83, which tells us how accurate our model is
on the data we used to construct the model.
So we know our model does a good job predicting
the data it's seen.
But we also want a model that does well
on new data or data it's never seen before so that we can use
the model to make predictions for later years.
For this particular application, Bordeaux wine buyers
profit from being able to predict the quality of a wine
years before it matures.
They know the values of the independent variables, age
and weather, but they don't know the price
the wine will eventually sell for.
So it's important to build a model that
does well at predicting data it's never seen before.
The data that we use to build a model
is often called the training data,
and the new data is often called the test data.
The accuracy of the model on the test data
is often referred to as out-of-sample accuracy.
Let's see how well our model performs
on some test data in R.
We have two data points that we did not use to build our model
in the file "wine_test.csv".

Let's load this new data file into R.
We'll call the data frame wineTest,
and we'll use the read.csv function to read in the data
file "wine_test.csv".

Make sure you're in the folder on your computer
containing this file before using the read.csv function.
If we take a look at the structure of wineTest
using the str function, we can see
that we have two observations and the same seven variables
as before.
To make predictions for these two test points,
we'll use the predict function.
We'll call the output predictTest,
and we'll use the predict function using model4,
our model with the four independent variables,
and then we need to indicate that the new data that we want
to make predictions for is in the data frame wineTest.

If we take a look at our predictions,
we can see that for the first data point we predict 6.7689,
and for the second data point we predict 6.6849.
If we look back at our str output,
we can see that the actual Price for the first data point
is 6.95, and the actual Price for the second data point
is 6.5.
So it looks like our predictions are pretty good,
but we can quantify this by computing the R-squared value
for our test set.
Recall that the formula for R-squared
is 1 minus the sum of squared errors divided
by the total sum of squares.
So let's start by computing the sum of squared errors
on our test set.
We'll call it SSE, and we want to use the sum function.
Follow that with two left parentheses,
and then the actual Price values,
wineTest$Price minus our predictions, predictTest.
Close the first parenthesis, and then
type the caret symbol and a 2 to square these,
close the second parenthesis, and hit Enter.
Now, let's compute the total sum of squares,
which we'll call SST.
This time, when we take the sum, we want to compute
the differences between the actual values,
wineTest$Price and the mean of Price on our training set.

Again, square these values and sum them up.
Now, to compute the test set R-squared, we can just type 1 -
SSE/SST.

So the R-squared on our test set is 0.79.
This is a pretty good out-of-sample R-squared.
But while we do well on these two test points,
keep in mind that our test set is really small.
We should increase the size of our test set
to be more confident about the out-of-sample accuracy
of our model.
We can compute the test set R-squared
for several different models.
This table shows the model R-squared
and the test set R-squared for the linear regression model
as we add more independent variables.
The model R-squared will always increase or stay the same
as we add more independent variables.
However, this is not true for the test set.
When selecting a model, we want one with a good model R-squared
but also with a good test set R-squared.
It looks like our model that uses AGST,
HarvestRain, Age, and WinterRain does very well
on the training data and on the test data.
But for this example, we need more data
to be conclusive since two data points in the test set
is not really enough to reach any conclusions.
Also, note here that the test set
R-squared can actually be negative.
The model R-squared is never negative
since our model can't do worse on the training
data than the baseline model.
However, our model can do worse on the test
data compared to the baseline model, leading
to a negative R-squared value.
We'll see in the next video how well Ashenfelter
did using this model to make predictions for later years.